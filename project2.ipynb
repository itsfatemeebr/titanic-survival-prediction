{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UTiyOwGc2M1o",
        "outputId": "fe2a73f5-9bf4-4cb3-e8d2-0fecc5208bff"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-ed095be10358>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ed095be10358>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    as.models import Model\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "as.models import Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# بارگیری مجموعه داده CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# نرمال‌سازی داده‌ها\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# ساخت Autoencoder\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# مدل Autoencoder\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# تنظیم EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# آموزش Autoencoder\n",
        "autoencoder.fit(x_train, x_train, epochs=50, batch_size=128,\n",
        "                validation_data=(x_test, x_test), callbacks=[early_stopping])\n",
        "\n",
        "# استخراج ویژگی‌ها از لایه Encoder\n",
        "encoder = Model(input_img, encoded)\n",
        "encoded_train = encoder.predict(x_train)\n",
        "encoded_test = encoder.predict(x_test)\n",
        "\n",
        "# تخت کردن ویژگی‌ها برای طبقه‌بندی\n",
        "encoded_train = encoded_train.reshape(encoded_train.shape[0], -1)\n",
        "encoded_test = encoded_test.reshape(encoded_test.shape[0], -1)\n",
        "\n",
        "# ساخت مدل طبقه‌بند\n",
        "clf = tf.keras.Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(encoded_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(100, activation='softmax')  # 100 کلاس برای CIFAR-100\n",
        "])\n",
        "\n",
        "clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# آموزش طبقه‌بند\n",
        "clf.fit(encoded_train, y_train, epochs=30, batch_size=128,\n",
        "        validation_data=(encoded_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# ارزیابی مدل\n",
        "test_loss, test_acc = clf.evaluate(encoded_test, y_test)\n",
        "print(\"Test Accuracy on CIFAR-100:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyDDsJAy2117"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xObGTe62_M-",
        "outputId": "0d01a0bc-7aab-4456-8952-becd5e511901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML3YhhxZ3F4k"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDfTraTW3Kqr"
      },
      "outputs": [],
      "source": [
        "input_img = Input(shape=(32, 32, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DODZq5I3Syu"
      },
      "outputs": [],
      "source": [
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "encoded = Conv2D(128, (3, 3), activation='relu', padding='same')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9iy4Qtl3a0_"
      },
      "outputs": [],
      "source": [
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgQ2ii6c3fIN"
      },
      "outputs": [],
      "source": [
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72WjUhVs3jYO"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xts2pZF3pi6",
        "outputId": "70b420ba-086f-4804-b5cf-beea7721cb04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 601ms/step - loss: 0.0216 - val_loss: 0.0059\n",
            "Epoch 2/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 598ms/step - loss: 0.0054 - val_loss: 0.0045\n",
            "Epoch 3/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 635ms/step - loss: 0.0043 - val_loss: 0.0040\n",
            "Epoch 4/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 633ms/step - loss: 0.0038 - val_loss: 0.0036\n",
            "Epoch 5/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 625ms/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 6/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 635ms/step - loss: 0.0033 - val_loss: 0.0031\n",
            "Epoch 7/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 635ms/step - loss: 0.0032 - val_loss: 0.0030\n",
            "Epoch 8/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 638ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 9/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 635ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 10/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 629ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 11/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 594ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 12/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 613ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 13/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 616ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 14/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 624ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 15/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 627ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 16/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 628ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 17/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 602ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 18/50\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 628ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 19/50\n",
            "\u001b[1m168/391\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 584ms/step - loss: 0.0021"
          ]
        }
      ],
      "source": [
        "autoencoder.fit(x_train, x_train, epochs=50, batch_size=128,\n",
        "                validation_data=(x_test, x_test), callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s93DgAr3umr"
      },
      "outputs": [],
      "source": [
        "encoder = Model(input_img, encoded)\n",
        "encoded_train = encoder.predict(x_train)\n",
        "encoded_test = encoder.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ3sDpPH8q59"
      },
      "outputs": [],
      "source": [
        "encoded_train = encoded_train.reshape(encoded_train.shape[0], -1)\n",
        "encoded_test = encoded_test.reshape(encoded_test.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-0QDGJV8vCI"
      },
      "outputs": [],
      "source": [
        "clf = tf.keras.Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(encoded_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(100, activation='softmax')  # 100 کلاس برای CIFAR-100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "o_wpNbXaHlmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(encoded_train, y_train, epochs=30, batch_size=128,\n",
        "        validation_data=(encoded_test, y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "rFzO5OlvHnrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = clf.evaluate(encoded_test, y_test)\n",
        "print(\"Test Accuracy on CIFAR-100:\", test_acc)\n"
      ],
      "metadata": {
        "id": "JuG-NOSVHrya"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}